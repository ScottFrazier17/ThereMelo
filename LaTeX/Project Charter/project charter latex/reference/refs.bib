@misc{Lant2010,
author = {Lant, Michael},
booktitle = {Software Development, Agile Methods and the Intersection of People Process and Technology},
title = {{How To Make Your Project Not Suck by Using an Agile Project Charter}},
url = {http://michaellant.com/2010/05/18/how-to-make-your-project-not-suck/},
year = {2010}
}
@book{Rubin2012,
author = {Rubin, Kenneth S},
edition = {1st},
isbn = {0137043295, 9780137043293},
publisher = {Addison-Wesley Professional},
title = {{Essential Scrum: A Practical Guide to the Most Popular Agile Process}},
year = {2012}
}
@techreport{USDefense2011,
institution = {U.S. Department of Defense},
pages = {2--7},
title = {{DOD Sample Phase I Proposal}},
url = {http://www.acq.osd.mil/osbp/sbir/sb/resources/sample-proposals.shtml},
year = {2011}
}
@article{Pan2021,
   abstract = {With the continuous development of society and rapid economic growth, intelligent music control technology has received more and more attention. At the same time, real-time motion tracking technology has also been developed more and more in the fields of virtual reality and human-machine control. This article is dedicated to developing a wireless music control system based on gesture tracking sensors. First, in the data collection part, an infrared sensor module based on the Internet of Things is used to automatically detect whether someone is approaching. When detecting that someone is approaching, the motion tracking sensor module captures and detects gestures and counts them through a counter. Then, the IoT data transmission module sends the acquired gesture information from the sending end to the receiving end. Finally, the particle swarm algorithm performs algorithmic intelligent processing and judgment on the transmitted data to realize wireless control of background music. After software and hardware debugging, a wireless music control model based on motion tracking was finally successfully established. The system has undergone a complete test, and the test results show that the system has strong stability. Users can easily control music equipment and achieve high accuracy of music control information.},
   author = {Na Pan and Na Pan},
   doi = {10.1109/ACCESS.2021.3064565},
   issn = {21693536},
   journal = {IEEE Access},
   title = {Research on Music Wireless Control Based on Motion Tracking Sensor and Internet of Things},
   volume = {9},
   year = {2021},
}
@misc{Vysocky2020,
   abstract = {In this analysis, we present results from measurements performed to determine the stability of a hand tracking system and the accuracy of the detected palm and finger’s position. Measurements were performed for the evaluation of the sensor for an application in an industrial robot-assisted assembly scenario. Human–robot interaction is a relevant topic in collaborative robotics. Intuitive and straightforward control tools for robot navigation and program flow control are essential for effective utilisation in production scenarios without unnecessary slowdowns caused by the operator. For the hand tracking and gesture-based control, it is necessary to know the sensor’s accuracy. For gesture recognition with a moving target, the sensor must provide stable tracking results. This paper evaluates the sensor’s real-world performance by measuring the localisation deviations of the hand being tracked as it moves in the workspace.},
   author = {Aleš Vysocký and Stefan Grushko and Petr Oščádal and Tomáš Kot and Ján Babjak and Rudolf Jánoš and Marek Sukop and Zdenko Bobovský},
   doi = {10.3390/s20154088},
   issn = {14248220},
   issue = {15},
   journal = {Sensors (Switzerland)},
   title = {Analysis of precision and stability of hand tracking with leap motion sensor},
   volume = {20},
   year = {2020},
}
@article{Muller2022,
   abstract = {Purpose: As human failure has been shown to be one primary cause for post-operative death, surgical training is of the utmost socioeconomic importance. In this context, the concept of surgical telestration has been introduced to enable experienced surgeons to efficiently and effectively mentor trainees in an intuitive way. While previous approaches to telestration have concentrated on overlaying drawings on surgical videos, we explore the augmented reality (AR) visualization of surgical hands to imitate the direct interaction with the situs. Methods: We present a real-time hand tracking pipeline specifically designed for the application of surgical telestration. It comprises three modules, dedicated to (1) the coarse localization of the expert’s hand and the subsequent (2) segmentation of the hand for AR visualization in the field of view of the trainee and (3) regression of keypoints making up the hand’s skeleton. The semantic representation is obtained to offer the ability for structured reporting of the motions performed as part of the teaching. Results: According to a comprehensive validation based on a large data set comprising more than 14,000 annotated images with varying application-relevant conditions, our algorithm enables real-time hand tracking and is sufficiently accurate for the task of surgical telestration. In a retrospective validation study, a mean detection accuracy of 98%, a mean keypoint regression accuracy of 10.0 px and a mean Dice Similarity Coefficient of 0.95 were achieved. In a prospective validation study, it showed uncompromised performance when the sensor, operator or gesture varied. Conclusion: Due to its high accuracy and fast inference time, our neural network-based approach to hand tracking is well suited for an AR approach to surgical telestration. Future work should be directed to evaluating the clinical value of the approach.},
   author = {Lucas Raphael Müller and Jens Petersen and Amine Yamlahi and Philipp Wise and Tim J. Adler and Alexander Seitel and Karl Friedrich Kowalewski and Beat Müller and Hannes Kenngott and Felix Nickel and Lena Maier-Hein},
   doi = {10.1007/s11548-022-02637-9},
   issn = {18616429},
   issue = {8},
   journal = {International Journal of Computer Assisted Radiology and Surgery},
   title = {Robust hand tracking for surgical telestration},
   volume = {17},
   year = {2022},
}
@inproceedings{Chronopoulos2021,
   abstract = {Quadrant is a new human-computer interface based on an array of distance sensors. The hardware consists of 4 time-of-flight detectors and is designed to detect the position, velocity, and orientation of the user's hand in free space. Signal processing is used to recognize gestures and other events, which we map to a variety of musical parameters to demonstrate possible applications. We have developed Quadrant as an open-hardware circuit board, which acts as a USB controller to a host computer.},
   author = {Chris Chronopoulos},
   doi = {10.21428/92fbeb44.761367fd},
   issn = {22204806},
   journal = {Proceedings of the International Conference on New Interfaces for Musical Expression},
   title = {Quadrant: A Multichannel, Time-of-Flight Based Hand Tracking Interface for Computer Music},
   year = {2021},
}
@article{Figueiredo2012,
   abstract = {This paper details the development and use of a gesture based inter- action game as an entertainment system but, also as a hand tracking evaluation tool. By using the ”air guitar” concept allied to mu- sic games interfaces, the proposed work performs an analysis of two different hand input methods. Firstly, a color glove detection method is used, then the Microsoft Kinect sensor is integrated pro- viding an attachment-free tracking method. Tests were performed and a set of users evaluated both the game and the tracking meth- ods. The results showed the impact of each tracking method on the user playing experience as well as the users understanding of the comparison game tool, validating the use of the proposed music game for the task.},
   author = {Lucas Silva Figueiredo and Veronica Teichrieb},
   issue = {X},
   journal = {XI Brazilian Symposium on Games and Digital Entertainment},
   title = {Kinect vs . Color Gloves : A Music Game tool for Hand Tracking Evaluation},
   year = {2012},
}
